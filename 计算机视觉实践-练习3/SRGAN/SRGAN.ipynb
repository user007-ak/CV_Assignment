{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1784814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.backends import cudnn\n",
    "\n",
    "# Random seed to maintain reproducible results\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "# Use GPU for training by default\n",
    "device = torch.device(\"cuda\", 0)\n",
    "# Turning on when the image size does not change during training can speed up training\n",
    "cudnn.benchmark = True\n",
    "# When evaluating the performance of the SR model, whether to verify only the Y channel image data\n",
    "only_test_y_channel = True\n",
    "# Model architecture name\n",
    "d_arch_name = \"discriminator\"\n",
    "g_arch_name = \"srresnet_x4\"\n",
    "# Model arch config\n",
    "in_channels = 3\n",
    "out_channels = 3\n",
    "channels = 64\n",
    "num_rcb = 16\n",
    "# Test upscale factor\n",
    "upscale_factor = 4\n",
    "# Current configuration parameter method\n",
    "mode = \"test\"\n",
    "# Experiment name, easy to save weights and log files\n",
    "exp_name = \"SRGAN_x4-Set5\"\n",
    "\n",
    "if mode == \"train\":\n",
    "    # Dataset address\n",
    "    train_gt_images_dir = f\"./data/ImageNet/SRGAN/train\"\n",
    "\n",
    "    test_gt_images_dir = f\"./data/Set5/GTmod12\"\n",
    "    test_lr_images_dir = f\"./data/Set5/LRbicx{upscale_factor}\"\n",
    "\n",
    "    gt_image_size = 96\n",
    "    batch_size = 16\n",
    "    num_workers = 4\n",
    "\n",
    "    # The address to load the pretrained model\n",
    "    pretrained_d_model_weights_path = f\"\"\n",
    "    pretrained_g_model_weights_path = f\"./results/SRResNet_x4-DIV2K/g_last.pth.tar\"\n",
    "\n",
    "    # Incremental training and migration training\n",
    "    resume_d_model_weights_path = f\"\"\n",
    "    resume_g_model_weights_path = f\"\"\n",
    "\n",
    "    # Total num epochs (200,000 iters)\n",
    "    epochs = 18\n",
    "\n",
    "    # Loss function weight\n",
    "    pixel_weight = 1.0\n",
    "    content_weight = 1.0\n",
    "    adversarial_weight = 0.001\n",
    "\n",
    "    # Feature extraction layer parameter configuration\n",
    "    feature_model_extractor_node = \"features.35\"\n",
    "    feature_model_normalize_mean = [0.485, 0.456, 0.406]\n",
    "    feature_model_normalize_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    # Optimizer parameter\n",
    "    model_lr = 1e-4\n",
    "    model_betas = (0.9, 0.999)\n",
    "    model_eps = 1e-8\n",
    "    model_weight_decay = 0.0\n",
    "\n",
    "    # Dynamically adjust the learning rate policy [100,000 | 200,000]\n",
    "    lr_scheduler_step_size = epochs // 2\n",
    "    lr_scheduler_gamma = 0.1\n",
    "\n",
    "    # How many iterations to print the training result\n",
    "    train_print_frequency = 100\n",
    "    valid_print_frequency = 1\n",
    "\n",
    "if mode == \"test\":\n",
    "    # Test data address\n",
    "    lr_dir = f\"./data/Set5/LRbicx{upscale_factor}\"\n",
    "    sr_dir = f\"./results/test/{exp_name}\"\n",
    "    gt_dir = f\"./data/Set5/GTmod12\"\n",
    "\n",
    "    g_model_weights_path = f\"./results/pretrained_models/SRGAN_x4-ImageNet-8c4a7569.pth.tar\"\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97f9d6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build `srresnet_x4` model successfully.\n",
      "Load `srresnet_x4` model weights `F:\\A研究生\\计算机视觉与应用实践\\计算机视觉实践-练习3\\SRGAN\\results\\pretrained_models\\SRGAN_x4-ImageNet-8c4a7569.pth.tar` successfully.\n",
      "Processing `F:\\A研究生\\计算机视觉与应用实践\\计算机视觉实践-练习3\\SRGAN\\data\\Set5\\LRbicx4\\baby.png`...\n",
      "Processing `F:\\A研究生\\计算机视觉与应用实践\\计算机视觉实践-练习3\\SRGAN\\data\\Set5\\LRbicx4\\bird.png`...\n",
      "Processing `F:\\A研究生\\计算机视觉与应用实践\\计算机视觉实践-练习3\\SRGAN\\data\\Set5\\LRbicx4\\butterfly.png`...\n",
      "Processing `F:\\A研究生\\计算机视觉与应用实践\\计算机视觉实践-练习3\\SRGAN\\data\\Set5\\LRbicx4\\head.png`...\n",
      "Processing `F:\\A研究生\\计算机视觉与应用实践\\计算机视觉实践-练习3\\SRGAN\\data\\Set5\\LRbicx4\\woman.png`...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import model\n",
    "from natsort import natsorted\n",
    "from numpy import ndarray\n",
    "\n",
    "def image_to_tensor(image: ndarray, range_norm: bool, half: bool) -> Tensor:\n",
    "    # Convert image data type to Tensor data type\n",
    "    tensor = torch.from_numpy(np.ascontiguousarray(image)).permute(2, 0, 1).float()\n",
    "\n",
    "    # Scale the image data from [0, 1] to [-1, 1]\n",
    "    if range_norm:\n",
    "        tensor = tensor.mul(2.0).sub(1.0)\n",
    "\n",
    "    # Convert torch.float32 image data type to torch.half image data type\n",
    "    if half:\n",
    "        tensor = tensor.half()\n",
    "\n",
    "    return tensor\n",
    "\n",
    "def tensor_to_image(tensor: Tensor, range_norm: bool, half: bool) -> Any:\n",
    "    if range_norm:\n",
    "        tensor = tensor.add(1.0).div(2.0)\n",
    "    if half:\n",
    "        tensor = tensor.half()\n",
    "\n",
    "    image = tensor.squeeze(0).permute(1, 2, 0).mul(255).clamp(0, 255).cpu().numpy().astype(\"uint8\")\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def preprocess_one_image(image_path: str, device: torch.device) -> Tensor:\n",
    "    image = cv2.imread(image_path).astype(np.float32) / 255.0\n",
    "\n",
    "    # BGR to RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert image data to pytorch format data\n",
    "    tensor = image_to_tensor(image, False, False).unsqueeze_(0)\n",
    "\n",
    "    # Transfer tensor channel image format data to CUDA device\n",
    "    tensor = tensor.to(device=device, memory_format=torch.channels_last, non_blocking=True)\n",
    "\n",
    "    return tensor\n",
    "\n",
    "model_names = sorted(\n",
    "    name for name in model.__dict__ if\n",
    "    name.islower() and not name.startswith(\"__\") and callable(model.__dict__[name]))\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    # Initialize the super-resolution bsrgan_model\n",
    "    g_model = model.__dict__[g_arch_name](in_channels=in_channels,\n",
    "                                                       out_channels=out_channels,\n",
    "                                                       channels=channels,\n",
    "                                                       num_rcb=num_rcb)\n",
    "    g_model = g_model.to(device=device)\n",
    "    print(f\"Build `{g_arch_name}` model successfully.\")\n",
    "\n",
    "    # Load the super-resolution bsrgan_model weights\n",
    "    checkpoint = torch.load(g_model_weights_path, map_location=lambda storage, loc: storage)\n",
    "    g_model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    print(f\"Load `{g_arch_name}` model weights \"\n",
    "          f\"`{os.path.abspath(g_model_weights_path)}` successfully.\")\n",
    "\n",
    "    # Create a folder of super-resolution experiment results\n",
    "    #make_directory(srgan_config.sr_dir)\n",
    "\n",
    "    # Start the verification mode of the bsrgan_model.\n",
    "    g_model.eval()\n",
    "\n",
    "    # Get a list of test image file names.\n",
    "    file_names = natsorted(os.listdir(lr_dir))\n",
    "    # Get the number of test image files.\n",
    "    total_files = len(file_names)\n",
    "\n",
    "    for index in range(total_files):\n",
    "        lr_image_path = os.path.join(lr_dir, file_names[index])\n",
    "        sr_image_path = os.path.join(sr_dir, file_names[index])\n",
    "        gt_image_path = os.path.join(gt_dir, file_names[index])\n",
    "\n",
    "        print(f\"Processing `{os.path.abspath(lr_image_path)}`...\")\n",
    "        lr_tensor = preprocess_one_image(lr_image_path, device)\n",
    "        gt_tensor = preprocess_one_image(gt_image_path, device)\n",
    "\n",
    "        # Only reconstruct the Y channel image data.\n",
    "        with torch.no_grad():\n",
    "            sr_tensor = g_model(lr_tensor)\n",
    "\n",
    "        # Save image\n",
    "        sr_image = tensor_to_image(sr_tensor, False, False)\n",
    "        sr_image = cv2.cvtColor(sr_image, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(sr_image_path, sr_image)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "773f209d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR_baby: 30.642098472244918\n",
      "SSIM_baby: 0.7820139\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "# 加载原始高分辨率图像和生成图像\n",
    "original_img = Image.open('data/Set5/GTmod12/baby.png').convert('RGB')\n",
    "generated_img = Image.open('results/test/SRGAN_x4-Set5/baby.png').convert('RGB')\n",
    "\n",
    "# 将图像转换为PyTorch张量\n",
    "original_img = transforms.ToTensor()(original_img).unsqueeze(0)\n",
    "generated_img = transforms.ToTensor()(generated_img).unsqueeze(0)\n",
    "\n",
    "# 计算PSNR\n",
    "max_value = 1.0  # 假设像素值的范围为[0,1]\n",
    "mse = torch.mean((generated_img - original_img) ** 2)\n",
    "psnr = 10 * math.log10(max_value**2 / mse)\n",
    "\n",
    "print('PSNR_baby:', psnr)\n",
    "\n",
    "# 计算 SSIM\n",
    "original_img = original_img.squeeze().permute(1,2,0).detach().numpy()\n",
    "generated_img = generated_img.squeeze().permute(1,2,0).detach().numpy()\n",
    "ssim_score = ssim(original_img,generated_img,win_size=3,multichannel=True,channel_axis=2,data_range=generated_img.max() - generated_img.min())\n",
    "\n",
    "print('SSIM_baby:', ssim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "855f97cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR_bird: 29.808428251277146\n",
      "SSIM_bird: 0.80076116\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "# 加载原始高分辨率图像和生成图像\n",
    "original_img = Image.open('data/Set5/GTmod12/bird.png').convert('RGB')\n",
    "generated_img = Image.open('results/test/SRGAN_x4-Set5/bird.png').convert('RGB')\n",
    "\n",
    "# 将图像转换为PyTorch张量\n",
    "original_img = transforms.ToTensor()(original_img).unsqueeze(0)\n",
    "generated_img = transforms.ToTensor()(generated_img).unsqueeze(0)\n",
    "\n",
    "# 计算PSNR\n",
    "max_value = 1.0  # 假设像素值的范围为[0,1]\n",
    "mse = torch.mean((generated_img - original_img) ** 2)\n",
    "psnr = 10 * math.log10(max_value**2 / mse)\n",
    "\n",
    "print('PSNR_bird:', psnr)\n",
    "\n",
    "# 计算 SSIM\n",
    "original_img = original_img.squeeze().permute(1,2,0).detach().numpy()\n",
    "generated_img = generated_img.squeeze().permute(1,2,0).detach().numpy()\n",
    "ssim_score = ssim(original_img,generated_img,win_size=3,multichannel=True,channel_axis=2,data_range=generated_img.max() - generated_img.min())\n",
    "\n",
    "print('SSIM_bird:', ssim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49c1ac41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR_butterfly: 25.255649471235454\n",
      "SSIM_butterfly: 0.7334442\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "# 加载原始高分辨率图像和生成图像\n",
    "original_img = Image.open('data/Set5/GTmod12/butterfly.png').convert('RGB')\n",
    "generated_img = Image.open('results/test/SRGAN_x4-Set5/butterfly.png').convert('RGB')\n",
    "\n",
    "# 将图像转换为PyTorch张量\n",
    "original_img = transforms.ToTensor()(original_img).unsqueeze(0)\n",
    "generated_img = transforms.ToTensor()(generated_img).unsqueeze(0)\n",
    "\n",
    "# 计算PSNR\n",
    "max_value = 1.0  # 假设像素值的范围为[0,1]\n",
    "mse = torch.mean((generated_img - original_img) ** 2)\n",
    "psnr = 10 * math.log10(max_value**2 / mse)\n",
    "\n",
    "print('PSNR_butterfly:', psnr)\n",
    "\n",
    "# 计算 SSIM\n",
    "original_img = original_img.squeeze().permute(1,2,0).detach().numpy()\n",
    "generated_img = generated_img.squeeze().permute(1,2,0).detach().numpy()\n",
    "ssim_score = ssim(original_img,generated_img,win_size=3,multichannel=True,channel_axis=2,data_range=generated_img.max() - generated_img.min())\n",
    "\n",
    "print('SSIM_butterfly:', ssim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a78e7c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR_head: 28.82089678146748\n",
      "SSIM_head: 0.6070606\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "# 加载原始高分辨率图像和生成图像\n",
    "original_img = Image.open('data/Set5/GTmod12/head.png').convert('RGB')\n",
    "generated_img = Image.open('results/test/SRGAN_x4-Set5/head.png').convert('RGB')\n",
    "\n",
    "# 将图像转换为PyTorch张量\n",
    "original_img = transforms.ToTensor()(original_img).unsqueeze(0)\n",
    "generated_img = transforms.ToTensor()(generated_img).unsqueeze(0)\n",
    "\n",
    "# 计算PSNR\n",
    "max_value = 1.0  # 假设像素值的范围为[0,1]\n",
    "mse = torch.mean((generated_img - original_img) ** 2)\n",
    "psnr = 10 * math.log10(max_value**2 / mse)\n",
    "\n",
    "print('PSNR_head:', psnr)\n",
    "\n",
    "# 计算 SSIM\n",
    "original_img = original_img.squeeze().permute(1,2,0).detach().numpy()\n",
    "generated_img = generated_img.squeeze().permute(1,2,0).detach().numpy()\n",
    "ssim_score = ssim(original_img,generated_img,win_size=3,multichannel=True,channel_axis=2,data_range=generated_img.max() - generated_img.min())\n",
    "\n",
    "print('SSIM_head:', ssim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1836c0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR_woman: 27.75483025739634\n",
      "SSIM_woman: 0.8140816\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "# 加载原始高分辨率图像和生成图像\n",
    "original_img = Image.open('data/Set5/GTmod12/woman.png').convert('RGB')\n",
    "generated_img = Image.open('results/test/SRGAN_x4-Set5/woman.png').convert('RGB')\n",
    "\n",
    "# 将图像转换为PyTorch张量\n",
    "original_img = transforms.ToTensor()(original_img).unsqueeze(0)\n",
    "generated_img = transforms.ToTensor()(generated_img).unsqueeze(0)\n",
    "\n",
    "# 计算PSNR\n",
    "max_value = 1.0  # 假设像素值的范围为[0,1]\n",
    "mse = torch.mean((generated_img - original_img) ** 2)\n",
    "psnr = 10 * math.log10(max_value**2 / mse)\n",
    "\n",
    "print('PSNR_woman:', psnr)\n",
    "\n",
    "# 计算 SSIM\n",
    "original_img = original_img.squeeze().permute(1,2,0).detach().numpy()\n",
    "generated_img = generated_img.squeeze().permute(1,2,0).detach().numpy()\n",
    "ssim_score = ssim(original_img,generated_img,win_size=3,multichannel=True,channel_axis=2,data_range=generated_img.max() - generated_img.min())\n",
    "\n",
    "print('SSIM_woman:', ssim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548209a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
